{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tatForge Quick Start Guide\n",
    "\n",
    "Extract structured data from PDF documents using **vision AI**.\n",
    "\n",
    "## What You'll Do\n",
    "\n",
    "1. **Load a PDF** and convert it to high-resolution images\n",
    "2. **Extract data** using GPT-4o vision via BAML\n",
    "3. **View results** as structured JSON\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "- `tatforge` installed: `pip install -e .` from project root\n",
    "- `OPENAI_API_KEY` environment variable set\n",
    "- A PDF file in the `pdfs/` directory\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n",
    "\n",
    "Load environment variables and verify all dependencies are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\n\n# Add project root to path\nsys.path.insert(0, '..')\n\n# Load environment variables\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# Check prerequisites\nchecks = []\n\n# Check OpenAI API key\napi_key = os.getenv(\"OPENAI_API_KEY\")\nif api_key:\n    checks.append((\"OPENAI_API_KEY\", f\"{api_key[:8]}...\", True))\nelse:\n    checks.append((\"OPENAI_API_KEY\", \"NOT SET\", False))\n\n# Check BAML\ntry:\n    import baml_py\n    from baml_client import b\n    # Verify the function we need exists\n    assert hasattr(b, 'ExtractDocumentFieldsFromImage'), \"BAML function missing\"\n    checks.append((\"baml-py + client\", \"OK\", True))\nexcept Exception as e:\n    checks.append((\"baml-py + client\", str(e), False))\n\n# Check tatforge.flows\ntry:\n    from tatforge.flows import file_to_pages\n    checks.append((\"tatforge.flows\", \"OK\", True))\nexcept ImportError as e:\n    checks.append((\"tatforge.flows\", str(e), False))\n\n# Check for PDFs\npdf_dir = Path(\"../pdfs\")\npdfs = list(pdf_dir.glob(\"*.pdf\")) if pdf_dir.exists() else []\nchecks.append((\"PDF files\", f\"{len(pdfs)} found\", len(pdfs) > 0))\n\n# Display results\nprint(\"Environment Check\")\nprint(\"=\" * 50)\nall_ok = True\nfor name, status, ok in checks:\n    icon = \"OK\" if ok else \"FAIL\"\n    print(f\"[{icon}] {name}: {status}\")\n    if not ok:\n        all_ok = False\nprint(\"=\" * 50)\n\nif all_ok:\n    print(\"All checks passed! Ready to proceed.\")\nelse:\n    print(\"Some checks failed. Fix issues before continuing.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Select and Load PDF\n",
    "\n",
    "Choose a PDF from the `pdfs/` directory and convert it to page images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tatforge.flows import file_to_pages\n",
    "\n",
    "# Find available PDFs\n",
    "pdf_dir = Path(\"../pdfs\")\n",
    "available_pdfs = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "if not available_pdfs:\n",
    "    raise FileNotFoundError(f\"No PDF files found in {pdf_dir.absolute()}\")\n",
    "\n",
    "print(\"Available PDFs:\")\n",
    "for i, pdf in enumerate(available_pdfs, 1):\n",
    "    print(f\"  {i}. {pdf.name}\")\n",
    "\n",
    "# Use the first PDF (change index to select different file)\n",
    "selected_pdf = available_pdfs[0]\n",
    "print(f\"\\nSelected: {selected_pdf.name}\")\n",
    "\n",
    "# Read and convert to images\n",
    "pdf_bytes = selected_pdf.read_bytes()\n",
    "print(f\"PDF size: {len(pdf_bytes):,} bytes\")\n",
    "\n",
    "pages = file_to_pages(selected_pdf.name, pdf_bytes)\n",
    "print(f\"Pages: {len(pages)}\")\n",
    "\n",
    "# Store first page for extraction\n",
    "page_image = pages[0].image\n",
    "print(f\"First page image: {len(page_image):,} bytes (PNG @ 300 DPI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Extraction Schema\n",
    "\n",
    "Specify what data you want to extract from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt = \"\"\"\n",
    "Extract all shipping information from this loading statement document.\n",
    "\n",
    "Return as JSON with this structure:\n",
    "{\n",
    "    \"document_title\": \"title of the document\",\n",
    "    \"last_updated\": \"date and author of last update\",\n",
    "    \"shipments\": [\n",
    "        {\n",
    "            \"slot_reference\": \"unique reference number\",\n",
    "            \"vessel_name\": \"name of the ship\",\n",
    "            \"port\": \"port name\",\n",
    "            \"eta_from\": \"ETA from date\",\n",
    "            \"eta_to\": \"ETA to date\",\n",
    "            \"commodity\": \"type of cargo\",\n",
    "            \"quantity_tonnes\": \"quantity in tonnes\",\n",
    "            \"exporter\": \"exporter name\",\n",
    "            \"loading_status\": \"status of loading\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Extraction prompt defined.\")\n",
    "print(f\"Prompt length: {len(extraction_prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run BAML Extraction\n",
    "\n",
    "Send the page image to GPT-4o vision for structured data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import baml_py\n",
    "from baml_client import b\n",
    "\n",
    "print(f\"Extracting from: {selected_pdf.name}\")\n",
    "print(\"Sending to GPT-4o vision...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Convert image to BAML format\n",
    "image_b64 = base64.b64encode(page_image).decode(\"utf-8\")\n",
    "baml_image = baml_py.Image.from_base64(\"image/png\", image_b64)\n",
    "\n",
    "# Run extraction (using sync client)\n",
    "result = b.ExtractDocumentFieldsFromImage(\n",
    "    document_image=baml_image,\n",
    "    extraction_prompt=extraction_prompt\n",
    ")\n",
    "\n",
    "print(\"Extraction complete!\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: View Extracted Data\n",
    "\n",
    "Display the structured JSON output from the extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"Extracted Data:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parse and pretty-print the JSON result\n",
    "try:\n",
    "    parsed = json.loads(result)\n",
    "    print(json.dumps(parsed, indent=2))\n",
    "except json.JSONDecodeError:\n",
    "    # If not valid JSON, print as-is\n",
    "    print(result)\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Process Multiple Pages (Optional)\n",
    "\n",
    "If your PDF has multiple pages, extract from each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pages) > 1:\n",
    "    print(f\"Processing all {len(pages)} pages...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_results = []\n",
    "    for i, page in enumerate(pages, 1):\n",
    "        print(f\"\\nPage {i}/{len(pages)}...\")\n",
    "        \n",
    "        # Convert and extract\n",
    "        img_b64 = base64.b64encode(page.image).decode(\"utf-8\")\n",
    "        img = baml_py.Image.from_base64(\"image/png\", img_b64)\n",
    "        \n",
    "        page_result = b.ExtractDocumentFieldsFromImage(\n",
    "            document_image=img,\n",
    "            extraction_prompt=extraction_prompt\n",
    "        )\n",
    "        \n",
    "        all_results.append({\n",
    "            \"page\": i,\n",
    "            \"data\": json.loads(page_result) if page_result.strip().startswith('{') else page_result\n",
    "        })\n",
    "        print(f\"  Done.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"All Pages Extracted:\")\n",
    "    print(json.dumps(all_results, indent=2))\n",
    "else:\n",
    "    print(\"Single page PDF - already processed above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've successfully:\n",
    "\n",
    "1. Loaded a PDF and converted it to 300 DPI images\n",
    "2. Extracted structured data using GPT-4o vision\n",
    "3. Parsed the results as JSON\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Customize the extraction prompt** for your document type\n",
    "- **Add more PDFs** to the `pdfs/` directory\n",
    "- **Use the CLI** for batch processing: `python main.py`\n",
    "- **Index with ColPali** for semantic search: `cocoindex setup && cocoindex update`\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [BAML Documentation](https://docs.boundaryml.com)\n",
    "- [CocoIndex Documentation](https://cocoindex.io/docs)\n",
    "- [Project Issues](https://github.com/Frosselet/COCOINDEX_LEARNING/issues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}