{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# tatForge Quick Start Guide with CocoIndex\n\nThis notebook demonstrates how to use **tatForge** with **CocoIndex** - the central orchestration framework that wires together:\n- **BAML** for structured LLM extraction with native PDF support\n- **Qdrant** for vector storage and semantic search\n- **SentenceTransformers** for text embeddings\n\n## Architecture\n\n```\nPDF Documents → CocoIndex Flow → BAML Extraction → Qdrant Storage\n                     ↓\n              Query Handler → Semantic Search\n```\n\n## Prerequisites\n\n| Component | Purpose | Setup |\n|-----------|---------|-------|\n| **CocoIndex** | Flow orchestration | `pip install cocoindex` |\n| **Qdrant** | Vector database | Docker: `docker run -p 6333:6333 qdrant/qdrant` |\n| **BAML** | LLM extraction | API key (OpenAI for GPT-4o) |\n| **SentenceTransformers** | Text embeddings | Included with CocoIndex |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Check Prerequisites\n\nLet's verify CocoIndex, Qdrant, and BAML are available."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\n\ndef check_prerequisites():\n    \"\"\"Check all CocoIndex prerequisites and report status.\"\"\"\n    status = {}\n    \n    # 1. Check CocoIndex\n    try:\n        import cocoindex\n        status[\"cocoindex\"] = {\"installed\": True, \"message\": f\"cocoindex {cocoindex.__version__ if hasattr(cocoindex, '__version__') else ''} is installed\"}\n    except ImportError:\n        status[\"cocoindex\"] = {\"installed\": False, \"message\": \"Missing: pip install cocoindex\"}\n    \n    # 2. Check Qdrant client and connection\n    try:\n        from qdrant_client import QdrantClient\n        status[\"qdrant_client\"] = {\"installed\": True, \"message\": \"qdrant-client is installed\"}\n        \n        qdrant_url = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n        try:\n            client = QdrantClient(url=qdrant_url, timeout=5)\n            collections = client.get_collections()\n            status[\"qdrant_server\"] = {\"running\": True, \"message\": f\"Qdrant running at {qdrant_url}\"}\n        except Exception as e:\n            status[\"qdrant_server\"] = {\"running\": False, \"message\": f\"Qdrant not running at {qdrant_url}\"}\n    except ImportError:\n        status[\"qdrant_client\"] = {\"installed\": False, \"message\": \"Missing: pip install qdrant-client\"}\n        status[\"qdrant_server\"] = {\"running\": False, \"message\": \"Install qdrant-client first\"}\n    \n    # 3. Check BAML\n    try:\n        import baml_py\n        status[\"baml\"] = {\"installed\": True, \"message\": \"baml-py is installed\"}\n    except ImportError:\n        status[\"baml\"] = {\"installed\": False, \"message\": \"Missing: pip install baml-py\"}\n    \n    # 4. Check BAML client (generated)\n    try:\n        from baml_client import b\n        status[\"baml_client\"] = {\"installed\": True, \"message\": \"BAML client generated\"}\n    except ImportError:\n        status[\"baml_client\"] = {\"installed\": False, \"message\": \"Run: baml-cli generate\"}\n    \n    # 5. Check for OpenAI API key (required for GPT-4o vision)\n    openai_key = os.getenv(\"OPENAI_API_KEY\")\n    if openai_key:\n        status[\"openai_api\"] = {\"configured\": True, \"message\": f\"OPENAI_API_KEY is set ({openai_key[:12]}...)\"}\n    else:\n        status[\"openai_api\"] = {\"configured\": False, \"message\": \"OPENAI_API_KEY not set (required for GPT-4o)\"}\n    \n    return status\n\n# Run checks\nprint(\"=\" * 60)\nprint(\"COCOINDEX PREREQUISITES CHECK\")\nprint(\"=\" * 60)\n\nstatus = check_prerequisites()\n\nall_ready = True\nfor component, info in status.items():\n    ready = info.get(\"installed\", False) or info.get(\"running\", False) or info.get(\"configured\", False)\n    icon = \"✅\" if ready else \"❌\"\n    print(f\"{icon} {component}: {info['message']}\")\n    if not ready:\n        all_ready = False\n\nprint(\"=\" * 60)\nif all_ready:\n    print(\"All prerequisites met! Ready for CocoIndex extraction.\")\nelse:\n    print(\"Some prerequisites missing. Follow the setup steps below.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Install CocoIndex (if missing)\n\nCocoIndex is the orchestration framework that manages data flows between BAML and Qdrant."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install CocoIndex (uncomment and run if not installed)\n# !pip install cocoindex\n\n# Verify installation\ntry:\n    import cocoindex\n    print(\"✅ CocoIndex installed successfully\")\nexcept ImportError:\n    print(\"❌ CocoIndex not installed. Uncomment the pip install line above and run.\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Step 3: Start Qdrant Vector Database\n\nQdrant stores the ColPali embeddings for semantic search. You can run it via Docker:\n\n```bash\n# In terminal, run:\ndocker run -p 6333:6333 -p 6334:6334 qdrant/qdrant\n```\n\nOr use Qdrant Cloud (free tier available at https://cloud.qdrant.io)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Check Qdrant connection\nfrom qdrant_client import QdrantClient\nimport os\n\nqdrant_url = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n\ntry:\n    client = QdrantClient(url=qdrant_url, timeout=5)\n    collections = client.get_collections()\n    print(f\"✅ Qdrant is running at {qdrant_url}\")\n    print(f\"   Collections: {len(collections.collections)}\")\nexcept Exception as e:\n    print(f\"❌ Cannot connect to Qdrant at {qdrant_url}\")\n    print(f\"   Error: {e}\")\n    print(f\"\\n   Start Qdrant with: docker run -p 6333:6333 qdrant/qdrant\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Step 4: Configure LLM API Key\n\nBAML uses an LLM (Claude or GPT-4) for structured extraction. Set your API key:\n\n**Option A**: Set in environment (recommended)\n```bash\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n# or\nexport OPENAI_API_KEY=\"sk-...\"\n```\n\n**Option B**: Set in this notebook (temporary)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set API key (uncomment and fill in your key)\nimport os\n\n# Option B: Set key directly (will only persist for this session)\n# os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\"  # Your Anthropic key\n# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # Or your OpenAI key\n\n# Check if API key is configured\nanthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\nopenai_key = os.getenv(\"OPENAI_API_KEY\")\n\nif anthropic_key:\n    print(f\"✅ ANTHROPIC_API_KEY is set ({anthropic_key[:12]}...)\")\nelif openai_key:\n    print(f\"✅ OPENAI_API_KEY is set ({openai_key[:12]}...)\")\nelse:\n    print(\"❌ No LLM API key configured\")\n    print(\"   Set ANTHROPIC_API_KEY or OPENAI_API_KEY above\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Initialize CocoIndex Flow\n\nImport and initialize the CocoIndex flow that orchestrates BAML extraction and Qdrant storage."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize CocoIndex\nimport os\nimport cocoindex\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Initialize CocoIndex\ncocoindex.init()\nprint(\"✅ CocoIndex initialized\")\n\n# Import the flow functions from our cocoindex_flow module\nimport sys\nsys.path.insert(0, '..')  # Add parent directory to path\n\nfrom cocoindex_flow import (\n    extract_document_fields,\n    extract_with_schema,\n    text_to_embedding,\n    document_extraction_flow,\n    search_documents,\n    QDRANT_URL,\n    QDRANT_COLLECTION,\n    PDF_PATH\n)\n\nprint(f\"✅ CocoIndex flow imported\")\nprint(f\"   PDF Path: {PDF_PATH}\")\nprint(f\"   Qdrant URL: {QDRANT_URL}\")\nprint(f\"   Collection: {QDRANT_COLLECTION}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# The CocoIndex flow will automatically:\n# 1. Load PDFs from the configured path (binary mode)\n# 2. Extract text using BAML with native PDF support\n# 3. Generate embeddings using SentenceTransformer\n# 4. Store results in Qdrant\n\n# To run the flow and index all PDFs, use CocoIndex CLI:\n# cocoindex run\n\n# Or programmatically trigger the flow (for development/testing):\nprint(\"CocoIndex Flow Architecture:\")\nprint(\"-\" * 40)\nprint(\"\"\"\n@cocoindex.flow_def(\"DocumentExtractionWithQdrant\")\ndef document_extraction_flow(flow_builder, data_scope):\n    \n    # 1. Load PDFs as binary\n    data_scope[\"documents\"] = flow_builder.add_source(\n        cocoindex.sources.LocalFile(path=\"pdfs\", binary=True)\n    )\n    \n    # 2. For each document...\n    with data_scope[\"documents\"].row() as doc:\n        # Extract using BAML (native PDF support!)\n        doc[\"extracted_text\"] = doc[\"content\"].transform(\n            extract_document_fields,\n            extraction_prompt=\"...\"\n        )\n        \n        # Generate embedding\n        doc[\"embedding\"] = text_to_embedding(doc[\"extracted_text\"])\n        \n        # Collect for storage\n        doc_embeddings.collect(...)\n    \n    # 3. Export to Qdrant\n    doc_embeddings.export(\n        \"doc_embeddings\",\n        cocoindex.targets.Qdrant(collection_name=\"documents\"),\n        primary_key_fields=[\"id\"]\n    )\n\"\"\")\nprint(\"-\" * 40)\nprint(\"✅ Flow ready. Run 'cocoindex run' to process documents.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: Direct BAML Extraction (without full flow)\n\nYou can also call the BAML extraction directly for testing. This shows how CocoIndex wraps BAML with native PDF support."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Direct BAML extraction example using native PDF support\nimport base64\nimport baml_py\nfrom pathlib import Path\nfrom baml_client import b\n\n# Select a PDF to extract from\npdf_path = Path(\"../pdfs/Bunge_loadingstatement_2025-09-25.pdf\")\nprint(f\"Extracting from: {pdf_path.name}\")\n\n# Read PDF as bytes and convert to BAML PDF type\npdf_bytes = pdf_path.read_bytes()\npdf_base64 = base64.b64encode(pdf_bytes).decode(\"utf-8\")\npdf = baml_py.Pdf.from_base64(pdf_base64)\n\nprint(f\"PDF size: {len(pdf_bytes):,} bytes\")\nprint(\"Converting to BAML PDF type (native support, no image conversion needed!)\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Step 7: Run BAML Extraction\n\nCall the BAML extraction function with the PDF document."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Run BAML extraction with custom prompt\nextraction_prompt = \"\"\"\nExtract all shipping information from this loading statement document.\nReturn as JSON with the following structure:\n{\n    \"document_title\": \"title of the document\",\n    \"last_updated\": \"date and author of last update\",\n    \"shipments\": [\n        {\n            \"slot_reference\": \"unique reference number\",\n            \"vessel_name\": \"name of the ship\",\n            \"port\": \"port name\",\n            \"eta_from\": \"ETA from date\",\n            \"eta_to\": \"ETA to date\",\n            \"commodity\": \"type of cargo\",\n            \"quantity_tonnes\": \"quantity in tonnes\",\n            \"exporter\": \"exporter name\",\n            \"loading_status\": \"status of loading\"\n        }\n    ]\n}\n\"\"\"\n\nprint(\"Running BAML extraction with GPT-4o (native PDF support)...\")\nprint(\"-\" * 60)\n\n# Call the BAML function (async)\nresult = await b.ExtractDocumentFieldsFromPDF(\n    document=pdf,\n    extraction_prompt=extraction_prompt\n)\n\nprint(\"✅ Extraction complete!\")\nprint(\"-\" * 60)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display extracted data - BAML returns Pydantic models\nprint(\"Extracted Data:\")\nprint(\"=\" * 60)\n\n# For ExtractDocumentFieldsFromPDF (returns str), print directly\nprint(result)\n\n# If using ExtractFromPDF (returns DocumentExtractionResult Pydantic model):\n# print(result.model_dump_json(indent=2))  # To JSON\n# print(result.model_dump())               # To dict"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 8: Semantic Search with CocoIndex Query Handler\n\nAfter running the CocoIndex flow, you can search documents using the query handler."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Search documents using the CocoIndex query handler\n# (Requires running 'cocoindex run' first to index documents)\n\ntry:\n    query = \"shipping vessel wheat loading\"\n    print(f\"Searching for: '{query}'\")\n    print(\"-\" * 60)\n    \n    results = search_documents(query)\n    \n    print(f\"Found {len(results.results)} results:\")\n    for i, r in enumerate(results.results, 1):\n        print(f\"\\n{i}. [{r['score']:.3f}] {r['filename']}\")\n        text = r.get('extracted_text', '')[:200]\n        print(f\"   {text}...\")\n        \nexcept Exception as e:\n    print(f\"Search error: {e}\")\n    print(\"\\nMake sure you've run 'cocoindex run' to index documents first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nYou've completed the CocoIndex + BAML + Qdrant quickstart! You learned how to:\n\n1. **Check prerequisites** - CocoIndex, Qdrant, BAML, OpenAI API key\n2. **Initialize CocoIndex** - Central orchestration framework\n3. **Understand the flow** - How CocoIndex wires BAML and Qdrant together\n4. **Direct BAML extraction** - Using native PDF support (`baml_py.Pdf.from_base64()`)\n5. **Semantic search** - Query documents via CocoIndex query handler\n\n## Key Architecture Points\n\n| Component | Role | CocoIndex Integration |\n|-----------|------|----------------------|\n| **BAML** | Structured extraction | `@cocoindex.op.function()` decorator |\n| **Qdrant** | Vector storage | `cocoindex.targets.Qdrant()` |\n| **SentenceTransformer** | Embeddings | `cocoindex.functions.SentenceTransformerEmbed()` |\n\n## Commands\n\n```bash\n# Run the CocoIndex flow to process all PDFs\ncocoindex run\n\n# Or run the flow script directly\npython cocoindex_flow.py\n```\n\n## Next Steps\n\n- Add more PDFs to the `pdfs/` directory\n- Customize extraction prompts in `cocoindex_flow.py`\n- Create custom BAML schemas in `baml_src/`\n- Read the [CocoIndex docs](https://cocoindex.io/docs)\n\n## Support\n\nFor issues: https://github.com/Frosselet/COCOINDEX_LEARNING/issues"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}